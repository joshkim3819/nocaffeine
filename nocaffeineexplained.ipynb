{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Code Explaination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this document is to walk you through the code that my caffeinated brain produced. Please keep in mind that this was the final version of countless versions. While I was transferring my files from my school computer (had to return) to my new computer, all the versions were corrupted, so I salvaged what I could from my physical notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big Questions: (\"A:\" was me answering the questions post completion)\n",
    "- What are the units to use?\n",
    "    A: Time, number of sips\n",
    "- How to track hands and not other moving objects in background?\n",
    "    A: Mediapipe allowed for face and hand tracking. If not present, then there would be no blue/green dots\n",
    "- What if it's a long sip vs short sip?\n",
    "    A: By not considering time for when the blue dot is in the detection threshold of the green, it counts 1 very long sip as 1 sip\n",
    "- How to track in real time?\n",
    "    A: Introducing the time library lets you keep a time tracker\n",
    "- How to differentiate desired action (drinking coffee) from undesired action (scratching head)\n",
    "    A: Creating a threshold (within 3% of camera width) allowed me to do scratch my head or fix my glasses without setting of detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imported Libraries\n",
    "- cv2: need for using compueter camera\n",
    "- mediapipe: need this library for pre made mapping for face and hands\n",
    "- time: need for study timer\n",
    "- math: need for addition and calculating distance threshold for +1 to action or +0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mp_holistic is required to map the face and hand\n",
    "mp_drawing is put in to digitally draw (Note: Probably don't need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "start_time = time.time()\n",
    "coffee_count = 0\n",
    "is_sipping = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the variables and the objective of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp_holistic.Holistic(\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Can't grab frame\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the detection thresholds for tracking the finger and the face and making sure that the camera is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv2.flip(frame, 1)\n",
    "image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "results = holistic.process(image)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "height, width, _ = image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditioning the camera\n",
    "- Changing view so it's a mirror rather than a Zoom meeting perspective\n",
    "- Changing colors to be compatible (OpenCV uses BGR; Mediapipe uses RGB)\n",
    "- Labeling image coordinates for tracking hand and face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_near_mouth = False \n",
    "\n",
    "if results.face_landmarks:\n",
    "    mouth_x = (results.face_landmarks.landmark[13].x +\n",
    "               results.face_landmarks.landmark[14].x) / 2 * width\n",
    "    mouth_y = (results.face_landmarks.landmark[13].y +\n",
    "               results.face_landmarks.landmark[14].y) / 2 * height\n",
    "    cv2.circle(image, (int(mouth_x), int(mouth_y)), 5, (0, 255, 0), -1)\n",
    "else:\n",
    "    mouth_x, mouth_y = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pre set conditions to find face and plot a green dot at mouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results.left_hand_landmarks:\n",
    "    left_index = results.left_hand_landmarks.landmark[12]\n",
    "    left_x = int(left_index.x * width)\n",
    "    left_y = int(left_index.y * height)\n",
    "    cv2.circle(image, (left_x, left_y), 5, (255, 0, 0), -1)\n",
    "    distance = math.dist([left_x, left_y], [mouth_x, mouth_y])\n",
    "    if distance < width * 0.03:\n",
    "        hand_near_mouth = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the pre set conditions to see if the left hand is present and plotting with blue dot.\n",
    "- used the middle finger (setting 12)\n",
    "\n",
    "If the blue dot (middle finger) is within 3% of the camera frame's width to the green dot (mouth), then count it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results.right_hand_landmarks:\n",
    "    right_index = results.right_hand_landmarks.landmark[12]\n",
    "    right_x = int(right_index.x * width)\n",
    "    right_y = int(right_index.y * height)\n",
    "    cv2.circle(image, (right_x, right_y), 5, (255, 0, 0), -1)\n",
    "    distance = math.dist([left_x, left_y], [mouth_x, mouth_y])\n",
    "    if distance < width * 0.03:\n",
    "        hand_near_mouth = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the same exact setting for the right hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hand_near_mouth and not is_sipping:\n",
    "    coffee_count += 1\n",
    "    is_sipping = True\n",
    "elif not hand_near_mouth:\n",
    "    is_sipping = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting up the times that I sipped the coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "cv2.putText(image, f\"Coffee Sip Count: {coffee_count}\", (10, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "cv2.putText(image, f\"Study Timer: {int(elapsed_time)} sec\", (10, 70),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "cv2.imshow('Coffee Drinking Count', image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeps track of the time that passed while displaying the timer and the coffee sip count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exiting out of the model by clicking \"q\" on keyboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomalib_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
